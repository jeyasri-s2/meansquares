{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "colab": {
      "name": "1.0.0 - Flappy Bird - DQN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarsanjani/meansquares/blob/master/temp/1_0_0_Flappy_Bird_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCJgc8_BMjhs"
      },
      "source": [
        " <a href=\"https://colab.research.google.com/github/ypeleg/keras_rl_tutorial/blob/master/1.0.0%20-%20Flappy%20Bird%20-%20DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyomvuSyMjht"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEZvZY46Mjhu"
      },
      "source": [
        "<div> \n",
        "    <center><strong><h5>Reinforcement Learning Tutorial!</h5></strong></center>\n",
        "    <center><strong><h2>1.0.0 Hands On Tutorial - Flappy Bird</h2></strong></center> \n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ysD_JtMjhv"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zInVeyMlMjhv"
      },
      "source": [
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td><img src=\"https://github.com/aarsanjani/meansquares/blob/master/temp/img/animation1.gif?raw=1\" width=\"400\"></td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0YSfOo_Mjhw"
      },
      "source": [
        "### Installations & Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5E4yPihMjhx",
        "outputId": "1820ab5d-c500-471a-f63c-e914e3a321bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pygame\n",
        "import os \n",
        "os.chdir('/content')\n",
        "os.listdir('.')\n",
        "if not os.path.exists('keras_rl_tutorial'): os.system('git clone https://github.com/ypeleg/keras_rl_tutorial/')\n",
        "os.chdir('keras_rl_tutorial')\n",
        "os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "import pygame.transform\n",
        "import pygame.display\n",
        "pygame.display.init()\n",
        "import sys \n",
        "import keras\n",
        "import pygame \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import pylab\n",
        "import sys\n",
        "sys.path.append(\"game/\")\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from game import wrapped_flappy_bird as game\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD , Adam\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "# These are for the Live Demo on stage\n",
        "vstack = np.vstack\n",
        "argmax = np.argmax\n",
        "append = lambda x, y: np.append(x, y, axis=3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/4c/2ebe8ab1a695a446574bc48d96eb3503649893be8c769e7fafd65fd18833/pygame-2.0.0-cp36-cp36m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5MB 266kB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.0.0\n",
            "pygame 2.0.0 (SDL 2.0.12, python 3.6.9)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgkKSPoHMjh0"
      },
      "source": [
        "### Installations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AspjqPWGMjh1"
      },
      "source": [
        "MODE = 'Train'\n",
        "GAMMA = 0.99\n",
        "BATCH = 32\n",
        "\n",
        "def build_model():\n",
        "    inp = Input(shape=(80, 80, 4))\n",
        "    #X = Convolution2D(32, (8, 8), subsample=(4, 4), border_mode='same')(inp)\n",
        "    X = Convolution2D(32, 8, 4, padding='same')(inp)\n",
        "    X = Activation('relu')(X)\n",
        "    #X = Convolution2D(64, (4, 4), subsample=(2, 2), border_mode='same')(X)\n",
        "    X = Convolution2D(64, 4, 2, padding='same')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    #X = Convolution2D(64, (3, 3), subsample=(1, 1), border_mode='same')(X)\n",
        "    X = Convolution2D(64, 3, 1, padding='same')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = Dense(2)(X)\n",
        "    model = Model(inputs=inp, outputs=X)\n",
        "    model.summary()\n",
        "    model.compile(loss='mse', optimizer=Adam(lr=1e-4))\n",
        "    return model\n",
        "\n",
        "def init_flappybird():\n",
        "    env = game.GameState()\n",
        "    x_t, r_0, terminal = env.step(0)\n",
        "    x_t = x_t.reshape(x_t.shape[1], x_t.shape[2])\n",
        "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
        "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])\n",
        "    return env, s_t"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CE2eXswMjh3"
      },
      "source": [
        "### Simple DQN For flappy bird "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ditW2jMLMjh4",
        "outputId": "2933d528-d339-4db3-a195-7d380762f23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Actual Algorithm Goes here:\n",
        "env, s_t = init_flappybird()\n",
        "model = build_model()\n",
        "D = deque()\n",
        "epsilon = 0.1\n",
        "\n",
        "\n",
        "vstack = np.vstack\n",
        "argmax = np.argmax\n",
        "append = lambda x, y: np.append(x, y, axis=3)\n",
        "\n",
        "\n",
        "while (True):\n",
        "    if random.random() <= epsilon: a_t = random.randint(0, 1)\n",
        "    else: a_t = argmax(model.predict(s_t))\n",
        "    epsilon -= 3.33e-08\n",
        "    x_t1, r_t, done = env.step(a_t)\n",
        "    s_t1 = append(x_t1, s_t[:, :, :, :3])\n",
        "    D.append((s_t, a_t, r_t, s_t1, done))\n",
        "    if len(D) > BATCH:\n",
        "        X, y = [], []\n",
        "        for i in range(BATCH):\n",
        "            state_t, action_t, reward_t, state_t1, done = random.choice(D)\n",
        "            X.append(state_t)\n",
        "            y.append(model.predict(state_t)[0])\n",
        "            if not done: y[-1][action_t] = reward_t + GAMMA * np.max(model.predict(state_t1))\n",
        "            else: y[-1][action_t] = reward_t\n",
        "        model.fit(vstack(X), vstack(y), epochs=1)\n",
        "    s_t = s_t1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r1/1 [==============================] - ETA: 0s - loss: 0.2061"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g96tr6jnPiEP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}